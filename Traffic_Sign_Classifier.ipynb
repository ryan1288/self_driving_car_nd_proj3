{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Project: Build a Traffic Sign Recognition Classifier\n",
    "This project explores the deep learning process, making use of TensorFlow to build a model (similar to the LeNet model) that is able to classify traffic signs with up to ~94% accuracy.\n",
    "\n",
    "In five main steps:\n",
    "* Step 0: Load the Data\n",
    "* Step 1: Data Summary & Exploration\n",
    "* Step 2: Design and Test a Model Architecture\n",
    "* Step 3: Test the Model on New images\n",
    "* Step 4: Visualize the Neural Network's State with Test Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "# Load, open, and assign training, validation, and testing data for German traffic signs\n",
    "\n",
    "# File address\n",
    "training_file = 'traffic_signs_data/train.p'\n",
    "validation_file = 'traffic_signs_data/valid.p'\n",
    "testing_file = 'traffic_signs_data/test.p'\n",
    "\n",
    "# Opening files\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "\n",
    "# Assigning features and label data (input and output)\n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_validation, y_validation = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Dataset Summary & Exploration\n",
    "\n",
    "The pickled data is a dictionary, but the two that will be used are the features (inputs) and labels (outputs)\n",
    "- `'features'` is a 4D array containing raw pixel data of the traffic sign images, (num examples, width, height, channels).\n",
    "- `'labels'` is a 1D array containing the label/class id of the traffic sign. The file `signnames.csv` contains id -> name mappings for each id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Replace each question mark with the appropriate value. \n",
    "### Use python, pandas or numpy methods rather than hard coding the results\n",
    "import numpy as np\n",
    "\n",
    "# Number of training examples\n",
    "n_train = len(X_train)\n",
    "\n",
    "# Number of validation examples\n",
    "n_validation = len(X_validation)\n",
    "\n",
    "# Number of testing examples.\n",
    "n_test = len(X_test)\n",
    "\n",
    "# Shape of traffic sign images\n",
    "image_shape = X_train[0].shape\n",
    "\n",
    "# Number of unique classes/labels\n",
    "n_classes = np.amax(y_train) - np.amin(y_train) + 1\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of validation examples =\", n_validation)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "# Choose a random image from the data set\n",
    "index = random.randint(0, len(X_train))\n",
    "image = X_train[index].squeeze()\n",
    "\n",
    "# Plot the random image and display the label as well\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "print(y_train[index])\n",
    "\n",
    "# Create histograms of labels for each data set\n",
    "train_hist, train_edges = np.histogram(y_train, bins = range(43))\n",
    "valid_hist, valid_edges = np.histogram(y_validation, bins = range(43))\n",
    "test_hist, test_edges = np.histogram(y_test, bins = range(43))\n",
    "\n",
    "# Plot histograms\n",
    "plt.bar(train_edges[:-1], train_hist, width = 1)\n",
    "plt.title('Training Data')\n",
    "plt.xlim(min(train_edges), max(train_edges))\n",
    "plt.show()\n",
    "plt.bar(valid_edges[:-1], valid_hist, width = 1)\n",
    "plt.title('Validation Data')\n",
    "plt.xlim(min(valid_edges), max(valid_edges))\n",
    "plt.show()\n",
    "plt.bar(test_edges[:-1], test_hist, width = 1)\n",
    "plt.title('Testing Data')\n",
    "plt.xlim(min(valid_edges), max(valid_edges))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Step 2: Design and Test the Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the Data Set (normalization, grayscale, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain teh shuffle to randomize the batches for each run\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "# Normalize the data of 8 bits to be between [-1,1) instead of [0,255]\n",
    "X_train = X_train/128 - 1\n",
    "X_validation = X_validation/128 - 1\n",
    "X_test = X_test/128 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Set some of the Hyperparameters\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 32\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "# Create LeNet-adjusted architecture\n",
    "def LeNet(x):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    # Weights creates as a dictionary using the truncated_normal using below input shapes\n",
    "    weights = {\n",
    "        'wc1': tf.Variable(tf.truncated_normal(shape = (5, 5, 3, 6), mean = mu, stddev = sigma)),\n",
    "        'wc2': tf.Variable(tf.truncated_normal(shape = (5, 5, 6, 16), mean = mu, stddev = sigma)),\n",
    "        'wd1': tf.Variable(tf.truncated_normal(shape = (400, 120), mean = mu, stddev = sigma)),\n",
    "        'wd2': tf.Variable(tf.truncated_normal(shape = (120, 84), mean = mu, stddev = sigma)),\n",
    "        'out': tf.Variable(tf.truncated_normal(shape = (84, 43), mean = mu, stddev = sigma))\n",
    "    }\n",
    "\n",
    "    biases = {\n",
    "        'bc1': tf.Variable(tf.zeros(6)),\n",
    "        'bc2': tf.Variable(tf.zeros(16)),\n",
    "        'bd1': tf.Variable(tf.zeros(120)),\n",
    "        'bd2': tf.Variable(tf.zeros(84)),\n",
    "        'out': tf.Variable(tf.zeros(43))\n",
    "    }\n",
    "    \n",
    "    # Set strides to be 1\n",
    "    strides_set = [1, 1, 1, 1]\n",
    "\n",
    "    # Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "    layer1 = tf.nn.conv2d(x,weights['wc1'], strides=strides_set, padding='VALID')\n",
    "    layer1 = tf.add(layer1,biases['bc1'])\n",
    "    # ReLU Activation\n",
    "    layer1 = tf.nn.relu(layer1)\n",
    "    # Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    k_size = [1, 2, 2, 1]\n",
    "    pool_stride = [1, 2, 2, 1]\n",
    "    pool1 = tf.nn.max_pool(layer1, ksize=k_size, strides=pool_stride, padding='VALID')\n",
    "    \n",
    "    # Layer 2: Convolutional. Output = 10x10x16.\n",
    "    layer2 = tf.nn.conv2d(pool1,weights['wc2'], strides=strides_set, padding='VALID')\n",
    "    layer2 = tf.add(layer2,biases['bc2'])    \n",
    "    # ReLU Activation\n",
    "    layer2 = tf.nn.relu(layer2)\n",
    "    # Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    pool2 = tf.nn.max_pool(layer2, ksize=k_size, strides=pool_stride, padding='VALID')\n",
    "                           \n",
    "    # Flatten. Input = 5x5x16. Output = 400.\n",
    "    flatten = tf.reshape(pool2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "                           \n",
    "    # Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "    fc1 = tf.add(tf.matmul(flatten,weights['wd1']),biases['bd1'])\n",
    "    # ReLU Activation and dropout\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "\n",
    "    # Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    fc2 = tf.add(tf.matmul(fc1,weights['wd2']),biases['bd2'])\n",
    "    # ReLU Activation and Dropout\n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "    fc2 = tf.nn.dropout(fc2, keep_prob)\n",
    "\n",
    "    # Layer 5: Fully Connected. Input = 84. Output = 43.\n",
    "    logits = tf.add(tf.matmul(fc2,weights['out']),biases['out'])\n",
    "    \n",
    "    return logits, layer1, pool1, layer2, pool2, fc1, fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and Labels\n",
    "`x` is a placeholder for a batch of input images.\n",
    "`y` is a placeholder for a batch of output labels.\n",
    "One-hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validate and Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Hyperparameter learning rate\n",
    "rate = 0.0005\n",
    "\n",
    "# Output all layers of CNN, then set cross entropy using softmax, loss calculation, AdamOptimizer, and training operation\n",
    "logits, layer1, pool1, layer2, pool2, fc1, fc2 = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation\n",
    "Evaluate how well the loss and accuracy of the model for a given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compared the maximum softmax prediction to the label, check if the label is correct\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "# Calculate the accuracy of the prediction\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Initialize the model saving function\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Create evaluate function for testing purposes\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y, keep_prob:1})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model\n",
    "Run the training data through the training pipeline to train the model.\n",
    "* Before each epoch, shuffle the training set.\n",
    "* After each epoch, measure the loss and accuracy of the validation set.\n",
    "* Save the model after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y, keep_prob: 0.6})\n",
    "            \n",
    "        validation_accuracy = evaluate(X_validation, y_validation)\n",
    "        training_accuracy = evaluate(X_train, y_train)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Training Accuracy = {:.3f}\".format(training_accuracy))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "The model is run one time using the testing batch of german traffic signs, providing a more accurate final accuracy % of classifying traffic signs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "\n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Test the Model on New Images\n",
    "\n",
    "Five pictures of German traffic signs were obtained from a Google image search, and the model is run to test them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Output the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "# Load the images from the local folder\n",
    "def load_images(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = mpimg.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'new_images/'\n",
    "images = load_images(filepath)\n",
    "\n",
    "# Show the five images\n",
    "fig = plt.figure(figsize=(5, 5))  # width, height in inches\n",
    "\n",
    "fig,ax = plt.subplots(1,5)\n",
    "for i in range(5):\n",
    "    ax[i].imshow(images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Sign Type for Each Image\n",
    "Labels should be (in order)\n",
    "\n",
    "* 13: Yield\n",
    "* 34: Turn left ahead\n",
    "* 40: Roundabout mandatory\n",
    "* 36: Go straight or right\n",
    "* 12: Priority road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    images[i] = images[i]/128 - 1\n",
    "images = np.asarray(images)\n",
    "images_labels = np.transpose([13, 34, 40, 36, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The session is re-initialize and the model is loaded. \n",
    "# Then both the predictions and comparisons to the correct label is given\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    prediction = sess.run(tf.argmax(logits, 1), feed_dict={x: images, y: images_labels, keep_prob:1})\n",
    "    print(prediction)\n",
    "    compare = sess.run(correct_prediction, feed_dict={x: images, y: images_labels, keep_prob:1})\n",
    "    print(compare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The accuracy is calculated for the five new images (out of 1)\n",
    "overall_accuracy = sum(compare)/5\n",
    "print(overall_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Top 5 Softmax Probabilities For Each Image Found on the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the five images below, `the tf.nn.top_k` function finds the top 5 softmax confidence calculation for each sign.\n",
    "The assoiated indices (labels) are provided in the exact same order (most likle to least likely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    top_5 = sess.run(tf.nn.softmax(logits, 1), feed_dict={x: images, y: images_labels, keep_prob:1})\n",
    "    top_softmax = sess.run(tf.nn.top_k(tf.constant(top_5), k=5))\n",
    "    print(top_softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Visualize the Neural Network's State with Test Images\n",
    "\n",
    "Visualizing the create CNN's state at different layers of the model below using feature maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_input: the test image being fed into the network to produce the feature maps\n",
    "# tf_activation: should be a tf variable name used during your training procedure that represents the calculated state of a specific weight layer\n",
    "# activation_min/max: can be used to view the activation contrast in more detail, by default matplot sets min and max to the actual min and max values of the output\n",
    "# plt_num: used to plot out multiple different weight feature map sets on the same block, just extend the plt number for each new feature map entry\n",
    "\n",
    "def outputFeatureMap(image_input, tf_activation, activation_min=-1, activation_max=-1 ,plt_num=1):\n",
    "    # Here make sure to preprocess your image_input in a way your network expects\n",
    "    # with size, normalization, ect if needed\n",
    "    # image_input =\n",
    "    # Note: x should be the same name as your network's tensorflow data placeholder variable\n",
    "    # If you get an error tf_activation is not defined it may be having trouble accessing the variable from inside a function\n",
    "    activation = tf_activation.eval(session=sess,feed_dict={x : image_input})\n",
    "    featuremaps = activation.shape[3]\n",
    "    plt.figure(plt_num, figsize=(15,15))\n",
    "    for featuremap in range(featuremaps):\n",
    "        plt.subplot(6,8, featuremap+1) # sets the number of feature maps to show on each row and column\n",
    "        plt.title('FeatureMap ' + str(featuremap)) # displays the feature map number\n",
    "        if activation_min != -1 & activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmin =activation_min, vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_min !=-1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmin=activation_min, cmap=\"gray\")\n",
    "        else:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", cmap=\"gray\")\n",
    "\n",
    "# Specifically, only the second layer is observed as it contains more details\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    sess.run(outputFeatureMap(images, layer2))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
